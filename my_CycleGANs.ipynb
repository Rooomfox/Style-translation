{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Neu80ac4fKVF"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "!pip install q torchinfo\n",
        "from torchinfo import summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "raYo6GWYfPPF"
      },
      "outputs": [],
      "source": [
        "class FeatureBlock(nn.Module):\n",
        "  def __init__(self, input_channel, output_channel, kernel_size = 7, padding = 3, stride = 1):\n",
        "    super().__init__()\n",
        "\n",
        "    self.conv = nn.Conv2d(input_channel, output_channel, kernel_size = kernel_size, padding = padding, stride = stride, padding_mode = 'reflect')\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.conv(x)\n",
        "\n",
        "class ContractBlock(nn.Module):\n",
        "  def __init__(self, input_channel, use_bn, kernel_size, activation = 'relu'):\n",
        "    super().__init__()\n",
        "\n",
        "    self.conv = nn.Conv2d(input_channel, 2 * input_channel, kernel_size = 4, padding = 1, stride = 2, padding_mode = 'reflect')\n",
        "    self.activation = nn.ReLU() if activation == 'relu' else nn.LeakyReLU(0.2)\n",
        "    self.norm = nn.InstanceNorm2d(2 * input_channel)\n",
        "    self.use_bn = use_bn #[True, False]\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv(x)\n",
        "    if self.use_bn:\n",
        "      x = self.norm(x)\n",
        "    x = self.activation(x)\n",
        "    return x\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "  def __init__(self, input_channel, hidden_size =64):\n",
        "    super().__init__()\n",
        "\n",
        "    self.feature = FeatureBlock(input_channel, hidden_size)\n",
        "    self.Contrack1 = ContractBlock(hidden_size, False, 4, 'leakyrelu')    #[2]\n",
        "    self.Contrack2 = ContractBlock(hidden_size * 2, True, 4, 'leakyrelu') #[4]\n",
        "    self.Contrack3 = ContractBlock(hidden_size * 4, True, 4, 'leakyrelu') #[8]\n",
        "\n",
        "    self.conv = nn.Conv2d( hidden_size * 8, 1, kernel_size = 1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.feature(x) # disentangled\n",
        "    x = self.Contrack1(x)\n",
        "    x = self.Contrack2(x)\n",
        "    x = self.Contrack3(x)\n",
        "    x = self.conv(x)\n",
        "    return x\n",
        "\n",
        "model = Discriminator(3)\n",
        "img = torch.randn((1,3, 256, 256))\n",
        "\n",
        "assert model(img).shape == (1, 1, 32 ,32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HjgKPzmtlFvj"
      },
      "outputs": [],
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "  def __init__(self, input_channel):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(input_channel, input_channel, kernel_size = 3, padding = 1, padding_mode = 'reflect')\n",
        "    self.norm1 = nn.InstanceNorm2d(input_channel)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.conv2 = nn.Conv2d(input_channel, input_channel, kernel_size = 3, padding = 1, padding_mode = 'reflect')\n",
        "    #self.norm2 = nn.InstanceNorm2d(input_channel)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x_orginal = x.clone()\n",
        "    x = self.conv1(x)\n",
        "    x = self.norm1(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.conv2(x)\n",
        "    x = self.norm1(x)\n",
        "    return x + x_orginal\n",
        "\n",
        "\n",
        "class ExpandBlock(nn.Module):\n",
        "  def __init__(self, input_channel, use_bn):\n",
        "    super(ExpandBlock, self).__init__()\n",
        "\n",
        "    self.conv = nn.ConvTranspose2d(input_channel, input_channel // 2, kernel_size = 3, stride = 2, padding = 1, output_padding = 1)\n",
        "    self.norm = nn.InstanceNorm2d(input_channel // 2)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.use_bn = use_bn  #[true , false]\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv(x)\n",
        "    if self.use_bn:\n",
        "      x = self.norm(x)\n",
        "\n",
        "    x = self.relu(x)\n",
        "    return x\n",
        "\n",
        "class Generator(nn.Module):\n",
        "  def __init__(self, input_channel, output_channel, hidden_channel = 64):\n",
        "    super().__init__()\n",
        "\n",
        "    self.feature1 = FeatureBlock(input_channel, hidden_channel)\n",
        "\n",
        "    self.contract1 = ContractBlock(hidden_channel, True, kernel_size = 3, activation = 'relu')\n",
        "    self.contract2 = ContractBlock(hidden_channel * 2, True, kernel_size = 3, activation = 'relu')\n",
        "\n",
        "    self.residual1 = ResidualBlock(hidden_channel * 4)\n",
        "    self.residual2 = ResidualBlock(hidden_channel * 4)\n",
        "    self.residual3 = ResidualBlock(hidden_channel * 4)\n",
        "    self.residual4 = ResidualBlock(hidden_channel * 4)\n",
        "    self.residual5 = ResidualBlock(hidden_channel * 4)\n",
        "    self.residual6 = ResidualBlock(hidden_channel * 4)\n",
        "    self.residual7 = ResidualBlock(hidden_channel * 4)\n",
        "    self.residual8 = ResidualBlock(hidden_channel * 4)\n",
        "    self.residual9 = ResidualBlock(hidden_channel * 4)\n",
        "\n",
        "    self.expand1 = ExpandBlock(hidden_channel * 4, use_bn = True)\n",
        "    self.expand2 = ExpandBlock(hidden_channel * 2, use_bn = True)\n",
        "\n",
        "    self.feature2 = FeatureBlock(hidden_channel, output_channel)\n",
        "    self.activation = nn.Tanh()\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.feature1(x)\n",
        "    x = self.contract1(x)\n",
        "    x = self.contract2(x)\n",
        "    x = self.residual1(x)\n",
        "    x = self.residual2(x)\n",
        "    x = self.residual3(x)\n",
        "    x = self.residual4(x)\n",
        "    x = self.residual5(x)\n",
        "    x = self.residual6(x)\n",
        "    x = self.residual7(x)\n",
        "    x = self.residual8(x)\n",
        "    x = self.residual9(x)\n",
        "    x = self.expand1(x)\n",
        "    x = self.expand2(x)\n",
        "    x = self.feature2(x)\n",
        "    x = self.activation(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "model = Generator(3, 3)\n",
        "img = torch.randn((1, 3, 256, 256))\n",
        "\n",
        "assert model(img).shape == (1, 3, 256, 256)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "coJRfP1V61q3"
      },
      "outputs": [],
      "source": [
        "summary( model = Generator(3,3),\n",
        "         input_size = (1,3,256,256),\n",
        "         col_names = ['input_size', 'output_size', 'num_params', 'trainable'],\n",
        "         row_settings = ['var_names'],\n",
        "         col_width=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iGIPl-gnspSS"
      },
      "outputs": [],
      "source": [
        "def Discriminator_loss(real_x, fake_x, disc_x, loss_fn):\n",
        "  A = disc_x(real_x)\n",
        "  B = disc_x(fake_x)\n",
        "\n",
        "  C = torch.ones_like(A)\n",
        "  D = torch.zeros_like(B)\n",
        "\n",
        "  return (loss_fn(A, C) + loss_fn(B, D)) / 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8MhDBSEWpTMm"
      },
      "outputs": [],
      "source": [
        "def Adversarial_loss(real_x, disc_y, gen_xy, loss_fn):\n",
        "  fake_y = gen_xy(real_x)\n",
        "  output = disc_y(fake_y)\n",
        "\n",
        "  return loss_fn(output, torch.ones_like(output)), fake_y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G4dS34INpZbf"
      },
      "outputs": [],
      "source": [
        "def Cycle_consistent_loss(real_x, fake_y, gen_yx, loss_fn):\n",
        "  cycle_x = gen_yx(fake_y)\n",
        "\n",
        "  return loss_fn(real_x, cycle_x), cycle_x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MUBGetk0pmpV"
      },
      "outputs": [],
      "source": [
        "def Identity_loss(real_x, gen_yx, loss_fn):\n",
        "  identity_x = gen_yx(real_x)\n",
        "\n",
        "  return loss_fn(real_x, identity_x), identity_x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KSegz-kqpqvk"
      },
      "outputs": [],
      "source": [
        "def Generator_loss(real_x, real_y, gen_xy, gen_yx, disc_x, disc_y,\n",
        "                   adv_loss_fn, identity_loss_fn, cycle_loss_fn,\n",
        "                   lambda_identity = 0.1, lambda_cycle = 10):\n",
        "\n",
        "  adver_loss1, fake_y = Adversarial_loss(real_x, disc_y, gen_xy, adv_loss_fn)\n",
        "  adver_loss2, fake_x = Adversarial_loss(real_y, disc_x, gen_yx, adv_loss_fn)\n",
        "\n",
        "  cycle_loss1 , cycle_x  = Cycle_consistent_loss(real_x, fake_y, gen_yx, cycle_loss_fn)\n",
        "  cycle_loss2 , cycle_y  = Cycle_consistent_loss(real_y, fake_x, gen_xy, cycle_loss_fn)\n",
        "\n",
        "  identity_loss1, identity_x  = Identity_loss(real_x, gen_yx, identity_loss_fn)\n",
        "  identity_loss2, identity_y  = Identity_loss(real_y, gen_xy, identity_loss_fn)\n",
        "\n",
        "  return (adver_loss1 + adver_loss2) + (cycle_loss1+cycle_loss2) * lambda_cycle + (identity_loss1 + identity_loss2) * lambda_identity, fake_x, fake_y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zFThA4rzp_Ar"
      },
      "outputs": [],
      "source": [
        "from tqdm.auto import tqdm\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import make_grid\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import random\n",
        "import os\n",
        "\n",
        "from PIL import Image\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "8a-yUZgb6HiW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LNOJDhfVqovb"
      },
      "outputs": [],
      "source": [
        "class VangoghDataset(Dataset):\n",
        "  def __init__(self, transform, mode = 'train'):\n",
        "    self.transform = transform\n",
        "    # pathA = '/content/drive/MyDrive/DL/Neural Style Transfer/Data/vangogh2photo/{}A/*.*'.format(mode) ## A: 400\n",
        "    # pathB = '/content/drive/MyDrive/DL/Neural Style Transfer/Data/vangogh2photo/{}B/*.*'.format(mode) ## B: 6287\n",
        "    pathA = '/content/drive/MyDrive/Colab Notebooks/images/Data/vangogh2photo/{}A/*.*'.format(mode) ## A: 400\n",
        "    pathB = '/content/drive/MyDrive/Colab Notebooks/images/Data/vangogh2photo/{}B/*.*'.format(mode) ## B: 6287\n",
        "    self.image_collectionA = sorted(glob.glob(pathA))\n",
        "    self.image_collectionB = sorted(glob.glob(pathB))\n",
        "    self.new_perm()\n",
        "\n",
        "  def new_perm(self):\n",
        "      self.randperm = torch.randperm(len(self.image_collectionB))[:len(self.image_collectionA)]\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "      item_A = self.transform(Image.open(self.image_collectionA[index % len(self.image_collectionA)]))\n",
        "      item_B = self.transform(Image.open(self.image_collectionB[self.randperm[index]]))\n",
        "      if index == len(self) - 1:\n",
        "          self.new_perm()\n",
        "      return (item_A - 0.5) * 2, (item_B - 0.5) * 2 #[-1,1]  #这段不理解\n",
        "\n",
        "  def __len__(self):\n",
        "      return min(len(self.image_collectionA), len(self.image_collectionB))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "djXhAiGB8-t6"
      },
      "outputs": [],
      "source": [
        "def show_tensor_images(image_tensor, num_images=25, size=(1, 28, 28)):\n",
        "    image_tensor = (image_tensor + 1) / 2\n",
        "    image_shifted = image_tensor\n",
        "    image_unflat = image_shifted.detach().cpu().view(-1, *size) ## torch(matrix) -> numpy(matrix)\n",
        "    image_grid = make_grid(image_unflat[:num_images], nrow=5)\n",
        "    plt.imshow(image_grid.permute(1, 2, 0)) ### plt( numpy() )\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k6spowRPrpBr"
      },
      "outputs": [],
      "source": [
        "####### DEFINE MODEL RELATED HYPERPARAMETERS ##########\n",
        "\n",
        "adv_criterion = nn.MSELoss()\n",
        "cycle_criterion = identity_criterion = nn.L1Loss()\n",
        "\n",
        "n_epoches = 30\n",
        "dim_X = 3\n",
        "dim_Y = 3\n",
        "\n",
        "batch_size = 1\n",
        "lr = 3e-4 ##\n",
        "\n",
        "target_shape = 256\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(286),\n",
        "    transforms.RandomCrop(target_shape),\n",
        "    transforms.RandomHorizontalFlip(0.5),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "dataset = VangoghDataset(transform=transform, mode = 'train')\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "#######################################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c9xIXkvb8ivl"
      },
      "outputs": [],
      "source": [
        "test_train, test_val = dataset[0]\n",
        "print(test_train.shape)\n",
        "print(test_val.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0G1i1ejUtQth"
      },
      "outputs": [],
      "source": [
        "gen_XY = Generator(dim_X, dim_Y).to(device)\n",
        "gen_YX = Generator(dim_Y, dim_X).to(device)\n",
        "gen_opt = torch.optim.Adam(list(gen_XY.parameters()) + list(gen_YX.parameters()), lr=lr, betas=(0.5, 0.999))\n",
        "disc_X = Discriminator(dim_X).to(device)\n",
        "disc_X_opt = torch.optim.Adam(disc_X.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "disc_Y = Discriminator(dim_Y).to(device)\n",
        "disc_Y_opt = torch.optim.Adam(disc_Y.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "\n",
        "def weights_init(m):\n",
        "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
        "        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n",
        "    if isinstance(m, nn.BatchNorm2d):\n",
        "        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n",
        "        torch.nn.init.constant_(m.bias, 0)\n",
        "\n",
        "gen_XY = gen_XY.apply(weights_init)\n",
        "gen_YX = gen_YX.apply(weights_init)\n",
        "disc_X = disc_X.apply(weights_init)\n",
        "disc_Y = disc_Y.apply(weights_init)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eA_-oTKNBEwf"
      },
      "outputs": [],
      "source": [
        "## 如果效果不好，可以适当的调大一点 n_epoches\n",
        "\n",
        "step= 0\n",
        "\n",
        "for epoch in range(n_epoches):\n",
        "  print('this is the {} epoch running '.format(epoch + 1))\n",
        "  for real_x, real_y in tqdm(dataloader):  ## tqdm： 进度条\n",
        "    step += 1\n",
        "    real_x = real_x.to(device)\n",
        "    real_y = real_y.to(device)\n",
        "\n",
        "    ##### Update disc X ######\n",
        "    disc_X_opt.zero_grad()    ##清空gradient\n",
        "    with torch.no_grad():     ## no_grad() 冻住生成器\n",
        "      fake_x = gen_YX(real_y)\n",
        "\n",
        "    disc_x_loss = Discriminator_loss(real_x, fake_x, disc_X, adv_criterion) ## 算loss\n",
        "    disc_x_loss.backward()  ## loss back propogation\n",
        "    disc_X_opt.step()       ## 更新参数\n",
        "\n",
        "    #### Update disc Y ####\n",
        "    disc_Y_opt.zero_grad()\n",
        "    with torch.no_grad():\n",
        "      fake_y = gen_XY(real_x)\n",
        "\n",
        "    disc_y_loss = Discriminator_loss(real_y, fake_y, disc_Y, adv_criterion)\n",
        "    disc_y_loss.backward()\n",
        "    disc_Y_opt.step()\n",
        "\n",
        "    ##### Update Genereator #####\n",
        "    gen_opt.zero_grad()\n",
        "\n",
        "    gen_loss, fake_x, fake_y =  Generator_loss(real_x, real_y, gen_XY, gen_YX, disc_X, disc_Y,\n",
        "                                                adv_criterion, identity_criterion, cycle_criterion)\n",
        "    gen_loss.backward()\n",
        "    gen_opt.step()\n",
        "\n",
        "    ###############################\n",
        "\n",
        "    if step % 20 == 0: ## 每20步，我看看我真实的image 和 生成的 image是什么样的\n",
        "      print('real image')\n",
        "      show_tensor_images(torch.cat([real_x, real_y]), size = (3, 256, 256))\n",
        "\n",
        "      print('fake image')\n",
        "      show_tensor_images(torch.cat([fake_x, fake_y]), size = (3, 256, 256))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/MyDrive/Colab Notebooks/images/Data/fujisan.jpg'\n",
        "\n",
        "content_img = Image.open(path)\n",
        "\n",
        "def prepocessing(img, image_shape = (256,256) , device = device):\n",
        "  transforms = transforms.Compose([\n",
        "      transforms.Resize(image_shape),\n",
        "      transforms.ToTensor(),  # (3, 256, 256)\n",
        "  ])\n",
        "  return transforms(img).unsqueeze(0).to(device) # (1,3,256,256)\n",
        "\n",
        "content_img = prepocessing(content_img) # [1, 3, 256, 256]\n",
        "\n",
        "print(content_img.image_shape)"
      ],
      "metadata": {
        "id": "x7NChHEXHrBA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(gen_XY(content_img)[0].permute(1,2,0))"
      ],
      "metadata": {
        "id": "gIln_njjJm1a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(gen_YX(content_img)[0].permute(1,2,0))"
      ],
      "metadata": {
        "id": "OaLT_DgxJlp6"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}